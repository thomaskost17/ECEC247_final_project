{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Module Initialization\n",
    "Here we will load all data and relevant modules. This will access helpful utilities aswell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "from utils.utils import *\n",
    "from nn.rnn import *\n",
    "import torch, torchaudio, torchvision\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (10.0, 8.0) # set default size of plots\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "plt.rcParams['image.cmap'] = 'gray'\n",
    "\n",
    "# for auto-reloading external modules\n",
    "# see http://stackoverflow.com/questions/1907993/autoreload-of-modules-in-ipython\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = np.load(add_path(\"X_test.npy\"))\n",
    "y_test = np.load(add_path(\"y_test.npy\"))\n",
    "person_train_valid = np.load(add_path(\"person_train_valid.npy\"))\n",
    "X_train_valid = np.load(add_path(\"X_train_valid.npy\"))\n",
    "y_train_valid = np.load(add_path(\"y_train_valid.npy\"))\n",
    "person_test = np.load(add_path(\"person_test.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check the shape of our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training/Valid data shape: (2115, 22, 1000)\n",
      "Test data shape: (443, 22, 1000)\n",
      "Training/Valid Target shape: (2115,)\n",
      "Test Target shape: (443,)\n",
      "Person Train/Valid shape: (2115, 1)\n",
      "Person Test shape: (443, 1)\n"
     ]
    }
   ],
   "source": [
    "print('Training/Valid data shape: {}'.format(X_train_valid.shape))\n",
    "print('Test data shape: {}'.format(X_test.shape))\n",
    "print('Training/Valid Target shape: {}'.format(y_train_valid.shape))\n",
    "print('Test Target shape: {}'.format(y_test.shape))\n",
    "print('Person Train/Valid shape: {}'.format(person_train_valid.shape))\n",
    "print('Person Test shape: {}'.format(person_test.shape))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preprocessing\n",
    "\n",
    "Here we will perfrom some data preprocessing to create a larger dataset and improve the generalization of our network.\n",
    "\n",
    "## Outline\n",
    "**Describe the preprocessing that will be done**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: preprocesing code from Zichao"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataset Augmentation\n",
    "\n",
    "Here we will augment our data set to increase the size of our training set. This will helop us to prevent overfitting and make our network more generalizable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Data set with gaussian noise\n",
    "std_data = np.std(X_train_valid)\n",
    "X_train_valid_gn = np.random.randn(*X_train_valid.shape)*std_data/10 +X_train_valid\n",
    "\n",
    "# Create data set with single sample shift\n",
    "X_train_valid_delay = np.roll(X_train_valid,1,axis=2)\n",
    "\n",
    "# Create data set that is scaled \n",
    "X_train_valid_half = X_train_valid/2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN Hyperparameter Tuning\n",
    "\n",
    "# Structure\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO : Instantiate an RNN object and perform hyperparameter tuning"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7783c1c403da32ab0836993f6933693559c492907b6c924b33c48fab4351724d"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('EEG_RNN')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
